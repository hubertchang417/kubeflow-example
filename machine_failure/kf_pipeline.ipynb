{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Creating a ML pipeline function for machine failure dataset\n",
    "#\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "import kfp.components as components\n",
    "from typing import NamedTuple\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def get_data_batch() -> NamedTuple('Output', [('mlpipeline_ui_metadata', 'UI_metadata')]):\n",
    "    \"\"\"\n",
    "    Function to get dataset and load modified data to minio bucket\n",
    "    \"\"\"\n",
    "    print(\"getting data\")\n",
    "    from minio import Minio\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import json\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    \n",
    "    ## get data from minio\n",
    "    minio_client = Minio(\n",
    "       \"<minio_ep>\",\n",
    "        access_key=\"<minio_accK>\",\n",
    "        secret_key=\"<minio_secK>\",\n",
    "        secure=False\n",
    "    )\n",
    "    minio_bucket = \"kubeflow\"\n",
    "\n",
    "    minio_client.fget_object(minio_bucket,f'datasets/machine_failure/machine_failure_dataset.csv',\"/tmp/machine_failure_dataset.csv\")\n",
    "    \n",
    "\n",
    "    ## load data\n",
    "    df = pd.read_csv(\"/tmp/machine_failure_dataset.csv\")\n",
    "    df_modify = pd.get_dummies(df, columns=['Machine_Type'], drop_first=True, dtype=int)\n",
    "    cols = ['Temperature', 'Vibration', 'Power_Usage', 'Humidity',\n",
    "       'Machine_Type_Lathe', 'Machine_Type_Mill', 'Failure_Risk']\n",
    "    df_modify_reorder = df_modify[cols]\n",
    "\n",
    "    ## split data\n",
    "\n",
    "    train_dataset, test_dataset = train_test_split(df_modify_reorder, test_size=0.2, random_state=42)\n",
    "    train_dataset.to_csv(\"/tmp/train_dataset.csv\", index=False)\n",
    "    test_dataset.to_csv(\"/tmp/test_dataset.csv\", index=False)\n",
    "\n",
    "    # save to dataset file, store in Minio\n",
    "    minio_client.fput_object(minio_bucket,f\"datasets/machine_failure/train_dataset.csv\",\"/tmp/train_dataset.csv\")\n",
    "    minio_client.fput_object(minio_bucket,f\"datasets/machine_failure/test_dataset.csv\",\"/tmp/test_dataset.csv\")\n",
    "\n",
    "    \n",
    "\n",
    "    # evidently ai\n",
    "    from evidently import ColumnMapping\n",
    "    from evidently.report import Report\n",
    "    from evidently.metric_preset import  DataQualityPreset  \n",
    "    from collections import namedtuple\n",
    "\n",
    "    column_mapping = ColumnMapping()\n",
    "    column_mapping.target = 'Failure_Risk'\n",
    "    column_mapping.numerical_features = ['Temperature', 'Vibration', 'Power_Usage', 'Humidity','Machine_Type_Lathe', 'Machine_Type_Mill']\n",
    "\n",
    "    report = Report(metrics=[DataQualityPreset()])\n",
    "    report.run(reference_data=None, current_data=df_modify_reorder, column_mapping=column_mapping)\n",
    "    # report.save_html(\"/tmp/report.html\")\n",
    "\n",
    "    metadata = {\n",
    "        'outputs' : [{\n",
    "        'type': 'web-app',\n",
    "        'storage': 'inline',\n",
    "        'source': report.get_html(),\n",
    "        }]\n",
    "    }\n",
    "    output = namedtuple('output', ['mlpipeline_ui_metadata'])\n",
    "    return output(json.dumps(metadata))\n",
    "\n",
    "def model_building(\n",
    "     rand_iter, rand_cv\n",
    ") -> NamedTuple('Output', [('mlpipeline_ui_metadata', 'UI_metadata'),('mlpipeline_metrics', 'Metrics')]):\n",
    "    \"\"\"\n",
    "    Build the model with Keras API\n",
    "    Export model parameters\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    from scipy.stats import uniform, randint\n",
    "    from xgboost import XGBClassifier\n",
    "    from minio import Minio\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import json\n",
    "    \n",
    "    ## get data from minio\n",
    "    minio_client = Minio(\n",
    "       \"<minio_ep>\",\n",
    "        access_key=\"<minio_accK>\",\n",
    "        secret_key=\"<minio_secK>\",\n",
    "        secure=False\n",
    "    )\n",
    "    minio_bucket = \"kubeflow\"\n",
    "    minio_client.fget_object(minio_bucket,f'datasets/machine_failure/train_dataset.csv',\"/tmp/train_dataset.csv\")\n",
    "    minio_client.fget_object(minio_bucket,f'datasets/machine_failure/test_dataset.csv',\"/tmp/test_dataset.csv\")\n",
    "    \n",
    "    train_dataset = pd.read_csv(\"/tmp/train_dataset.csv\")\n",
    "    train_input = train_dataset.drop(columns=['Failure_Risk'], axis=1)\n",
    "    train_tgt = train_dataset['Failure_Risk']\n",
    "    \n",
    "    test_dataset = pd.read_csv(\"/tmp/test_dataset.csv\")\n",
    "    test_input = test_dataset.drop(columns=['Failure_Risk'], axis=1)\n",
    "    test_tgt = test_dataset['Failure_Risk']\n",
    "    \n",
    "    model = XGBClassifier(random_state=42)\n",
    "    rand_grid = {\n",
    "        'n_estimators': randint(50, 500),\n",
    "        'max_depth': randint(5, 100),\n",
    "        'learning_rate':  uniform(0.01, 0.29),\n",
    "        'colsample_bytree': uniform(0.1, 0.9)\n",
    "    }\n",
    "\n",
    "    xg_random = RandomizedSearchCV(\n",
    "        estimator=model, \n",
    "        param_distributions=rand_grid,\n",
    "        n_iter=int(rand_iter),\n",
    "        cv=int(rand_cv),\n",
    "        verbose=1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    xg_random.fit(train_input, train_tgt)\n",
    "\n",
    "    test_pred = xg_random.best_estimator_.predict(test_input)\n",
    "\n",
    "    \n",
    "    from sklearn.metrics import accuracy_score, classification_report,confusion_matrix\n",
    "    import matplotlib.pyplot as plt\n",
    "    #show model summary - how it looks\n",
    "    test_accuracy = accuracy_score(test_tgt, test_pred)\n",
    "    test_report = classification_report(test_tgt, test_pred)\n",
    "    cm = confusion_matrix(test_tgt, test_pred)\n",
    "\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    vocab = list(np.unique(test_tgt))\n",
    "    data = []\n",
    "    for target_index, target_row in enumerate(cm):\n",
    "        for predicted_index, count in enumerate(target_row):\n",
    "            data.append((vocab[target_index], vocab[predicted_index], count))\n",
    "\n",
    "    df_cm = pd.DataFrame(data, columns=['target', 'predicted', 'count'])\n",
    "    cm_csv = df_cm.to_csv(header=False, index=False)\n",
    "    \n",
    "    metadata = {\n",
    "        \"outputs\": [\n",
    "            {\n",
    "                \"type\": \"confusion_matrix\",\n",
    "                \"format\": \"csv\",\n",
    "                \"schema\": [\n",
    "                    {'name': 'target', 'type': 'CATEGORY'},\n",
    "                    {'name': 'predicted', 'type': 'CATEGORY'},\n",
    "                    {'name': 'count', 'type': 'NUMBER'},\n",
    "                  ],\n",
    "                \"target_col\" : \"actual\",\n",
    "                \"predicted_col\" : \"predicted\",\n",
    "                \"source\": cm_csv,\n",
    "                \"storage\": \"inline\",\n",
    "                \"labels\": [0,1]\n",
    "            },\n",
    "            {\n",
    "                'storage': 'inline',\n",
    "                'source': '''# Model Overview\n",
    "## Model Summary\n",
    "\n",
    "```\n",
    "{}\n",
    "```\n",
    "\n",
    "'''.format(test_report),\n",
    "                'type': 'markdown',\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    metrics = {\n",
    "      'metrics': [{\n",
    "          'name': 'accuracy',\n",
    "          'numberValue':  float(test_accuracy),\n",
    "          'format' : \"PERCENTAGE\"\n",
    "        }]}\n",
    "    \n",
    "    ### Save model to minI\n",
    "    xg_random.best_estimator_.save_model(\"/tmp/model.bst\")\n",
    "    minio_client.fput_object(minio_bucket,f\"models/machine_failure/model.bst\", \"/tmp/model.bst\")\n",
    "\n",
    "    from collections import namedtuple\n",
    "    output = namedtuple('output', ['mlpipeline_ui_metadata', 'mlpipeline_metrics'])\n",
    "    return output(json.dumps(metadata),json.dumps(metrics))\n",
    "\n",
    "comp_get_data_batch = components.create_component_from_func(get_data_batch,base_image=\"python:3.10.0\",\n",
    "                                                            packages_to_install=['scikit-learn','minio','pandas','evidently'])\n",
    "comp_model_building = components.create_component_from_func(model_building,base_image=\"kubeflownotebookswg/jupyter-tensorflow-full:v1.7.0\",\n",
    "                                                            packages_to_install=['xgboost==1.6.0'])\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name='machine-failure-pipeline',\n",
    "    description='example pipeline for machine failure dataset'\n",
    ")\n",
    "def output_test( rand_iter, rand_cv):\n",
    "    \n",
    "    now = datetime.now()\n",
    "    v = now.strftime(\"%Y%m%d%H%M%S\")\n",
    "    minio_bucket = \"kubeflow\"\n",
    "\n",
    "    step1 = comp_get_data_batch()\n",
    "\n",
    "    \n",
    "    step2 = comp_model_building(rand_iter, rand_cv)\n",
    "    step2.after(step1)\n",
    "    seldon_deployment = {\n",
    "        \"apiVersion\": \"machinelearning.seldon.io/v1\",\n",
    "        \"kind\": \"SeldonDeployment\",\n",
    "        \"metadata\": {\n",
    "            \"name\": f\"machine-failure-{v}\",\n",
    "            \"namespace\": \"kubeflow-user-example-com\"\n",
    "        },\n",
    "        \"spec\": {\n",
    "            \"protocol\": \"seldon\",\n",
    "            \"predictors\": [\n",
    "                {\n",
    "                    \"name\": \"machine-failure-predictor\",\n",
    "                    \"replicas\": 1,\n",
    "                    \"graph\": {\n",
    "                        \"name\": \"classifier\",\n",
    "                        \"implementation\": \"XGBOOST_SERVER\",\n",
    "                        \"modelUri\": f\"s3://{minio_bucket}/models/machine_failure/\",\n",
    "                        \"envSecretRefName\": \"seldon-init-container-secret\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    step3 = dsl.ResourceOp(\n",
    "        name=f'seldon-deployment-{v}',\n",
    "        k8s_resource=seldon_deployment,\n",
    "        action=\"create\",\n",
    "        attribute_outputs={\"name\": \"{.metadata.name}\"}\n",
    "    )\n",
    "    step3.after(step2)\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    kubeflow_gateway_endpoint = \"<kubeflow-gateway-endpoint>\" # e.g. 172.0.0.1\n",
    "    authservice_session_cookie = \"<authservice_session_cookie>\"\n",
    "    \n",
    "    client = kfp.Client(host=f\"https://{kubeflow_gateway_endpoint}/pipeline\",\n",
    "                        cookies=f\"authservice_session={authservice_session_cookie}\",\n",
    "                        ssl_ca_cert=\"cert/tls.crt\") # need to store tls.crt before running the pipeline\n",
    "\n",
    "    arguments = {\n",
    "        \"rand_iter\": 1000,\n",
    "        \"rand_cv\": 5,\n",
    "    }\n",
    "\n",
    "\n",
    "    client.create_run_from_pipeline_func(output_test,arguments=arguments,experiment_name=\"machine-failure\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
